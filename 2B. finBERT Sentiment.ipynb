{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd27902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f205561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1115c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of class labels\n",
    "# class_labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "def predict_sentiment(text):\n",
    "    # Check if CUDA is available and set the device accordingly\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Move the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize the text and return a dictionary of tensors\n",
    "    class_labels = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    inputs = tokenizer(text, truncation=True, max_length=512, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "    # Move the inputs to the device\n",
    "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "\n",
    "    # Initialize a list to hold the probabilities for each chunk\n",
    "    chunk_probs = []\n",
    "\n",
    "    # Process the input tensors in chunks of 512 tokens\n",
    "    for i in range(0, inputs[\"input_ids\"].size(1), 512):\n",
    "        # Create a dictionary for the current chunk\n",
    "        chunk = {key: tensor[:, i:i+512] for key, tensor in inputs.items()}\n",
    "\n",
    "        # Run the chunk through the model and get the logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(**chunk).logits\n",
    "\n",
    "        # Compute the probabilities\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "        # Add the probabilities to the list\n",
    "        chunk_probs.append(probs)\n",
    "\n",
    "    # Average the probabilities across all chunks\n",
    "    avg_probs = torch.mean(torch.stack(chunk_probs), dim=0)\n",
    "\n",
    "    # Get the class with the highest average probability\n",
    "    class_idx = avg_probs.argmax().item()\n",
    "\n",
    "    # Get the sentiment score\n",
    "    sentiment_score = avg_probs.max().item()\n",
    "\n",
    "    # Get the individual probabilities for each sentiment class\n",
    "    negative_prob, neutral_prob, positive_prob = avg_probs.tolist()[0]\n",
    "\n",
    "    # Return the predicted class label, the sentiment score, and the individual probabilities\n",
    "    return class_labels[class_idx], sentiment_score, negative_prob, neutral_prob, positive_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01335f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function applies sentiment analysis to the entire dataframe, once it is done, it is stored into a pickle file\n",
    "def apply_sentiment_analysis(df): \n",
    "    # Apply the predict_sentiment function to the specified column\n",
    "    results = df['content'].apply(predict_sentiment)\n",
    "\n",
    "    # Unpack the results into separate Series\n",
    "    sentiments, sentiment_scores, negative_probs, neutral_probs, positive_probs = zip(*results)\n",
    "\n",
    "    # Add the new columns to the DataFrame\n",
    "    df['sentiment'] = sentiments\n",
    "    df['sentiment_score'] = sentiment_scores\n",
    "    df['negative_prob'] = negative_probs\n",
    "    df['neutral_prob'] = neutral_probs\n",
    "    df['positive_prob'] = positive_probs\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e142701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Processed finBERT S&P2006\n",
      "Time passed: 0hour:5min:10sec\n",
      "Successfully Processed finBERT S&P2007\n",
      "Time passed: 0hour:11min:27sec\n",
      "Successfully Processed finBERT S&P2008\n",
      "Time passed: 0hour:22min:19sec\n",
      "Successfully Processed finBERT S&P2009\n",
      "Time passed: 0hour:23min:39sec\n",
      "Successfully Processed finBERT S&P2010\n",
      "Time passed: 0hour:26min:35sec\n",
      "Successfully Processed finBERT S&P2011\n",
      "Time passed: 0hour:28min:56sec\n",
      "Successfully Processed finBERT S&P2012\n",
      "Time passed: 0hour:29min:37sec\n",
      "Successfully Processed finBERT S&P2013\n",
      "Time passed: 0hour:29min:41sec\n",
      "Successfully Processed finBERT S&P2014\n",
      "Time passed: 0hour:30min:12sec\n",
      "Successfully Processed finBERT S&P2015\n",
      "Time passed: 0hour:30min:30sec\n",
      "Successfully Processed finBERT S&P2016\n",
      "Time passed: 0hour:31min:15sec\n",
      "Successfully Processed finBERT S&P2017\n",
      "Time passed: 0hour:31min:36sec\n",
      "Successfully Processed finBERT S&P2018\n",
      "Time passed: 0hour:32min:13sec\n",
      "Successfully Processed finBERT S&P2019\n",
      "Time passed: 0hour:32min:40sec\n",
      "Successfully Processed finBERT S&P2020\n",
      "Time passed: 0hour:33min:25sec\n",
      "Successfully Processed finBERT S&P2021\n",
      "Time passed: 0hour:30min:31sec\n",
      "Successfully Processed finBERT S&P2022\n",
      "Time passed: 0hour:30min:52sec\n",
      "Successfully Processed finBERT S&P2023\n",
      "Time passed: 0hour:15min:0sec\n"
     ]
    }
   ],
   "source": [
    "for i in range(2006, 2024):\n",
    "    tic()\n",
    "    data = pd.read_pickle(f\"Clean_S&P{i}.pkl\")\n",
    "    proc = apply_sentiment_analysis(data)\n",
    "    proc.to_pickle(f'finBERT_S&P{i}.pkl')\n",
    "    print(f\"Successfully Processed finBERT S&P{i}\")\n",
    "    tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8193ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined pickle file has been saved as finBERT_S&P.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_pickles(start_year=2006, end_year=2023):\n",
    "    # Initialize an empty dataframe\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop over the range of years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        pickle_file = f\"finBERT_S&P{year}.pkl\"\n",
    "\n",
    "        # Check if the pickle file exists\n",
    "        if os.path.exists(pickle_file):\n",
    "            # Load the data from the pickle file\n",
    "            df = pd.read_pickle(pickle_file)\n",
    "            \n",
    "            # Append the data to the combined dataframe\n",
    "            combined_df = pd.concat([combined_df, df])\n",
    "        else:\n",
    "            print(f\"Pickle file for year {year} does not exist.\")\n",
    "    \n",
    "    # Save the combined dataframe to a new pickle file\n",
    "    combined_df.to_pickle(\"finBERT_S&P.pkl\")\n",
    "    print(\"Combined pickle file has been saved as finBERT_S&P.pkl\")\n",
    "\n",
    "# Call the function\n",
    "combine_pickles()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
